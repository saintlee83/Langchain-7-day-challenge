{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fdcca2",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c3b6a",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26f97cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# memory = ConversationBufferMemory()\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\" : \"Hi!\"}, {\"output\" : \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08268c",
   "metadata": {},
   "source": [
    "## ConverstionBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b13447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "  return_messages=True,\n",
    "  k=4\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "  memory.save_context({\"input\" : input}, {\"output\" : output})\n",
    "\n",
    "add_message(\"1\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f710e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"2\", \"2\")\n",
    "add_message(\"3\", \"3\")\n",
    "add_message(\"4\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04657ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='5', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='5', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb73e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"5\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960fb6a",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27161b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/x0tx5h514px6gvdl09jdn4rm0000gn/T/ipykernel_77313/1190634598.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.1)\n",
      "/var/folders/42/x0tx5h514px6gvdl09jdn4rm0000gn/T/ipykernel_77313/1190634598.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50171cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"South Kddorea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e67585a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Nicolas introduces himself as living in South Korea. The AI responds by expressing admiration for his location, wishing it could visit the country.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0edfba",
   "metadata": {},
   "source": [
    "## ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db944e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "460d2c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas lives in South Korea.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"who is Nicolas\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cebd0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Nicolas likes kimchi\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5544951e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas lives in South Korea. Nicolas likes kimchi.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"inputs\": \"what does nicolas like\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14967ee6",
   "metadata": {},
   "source": [
    "## Memory on LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e45fb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "  You are a helpful AI talking a human.\n",
      "\n",
      "  \n",
      "  Human: I live in Seoul\n",
      "  Your\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"AI: That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Off the shelf : General perpose chain\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "  llm=llm,\n",
    "  # max_token_limit=80\n",
    "  max_token_limit=120,\n",
    "  memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "  You are a helpful AI talking a human.\n",
    "\n",
    "  {chat_history}\n",
    "  Human: {question}\n",
    "  Your\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "  llm=llm,\n",
    "  memory=memory,\n",
    "  # prompt=PromptTemplate.from_template(\"{question}\"),\n",
    "  prompt=PromptTemplate.from_template(template),\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de2b3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "  You are a helpful AI talking a human.\n",
      "\n",
      "  Human: I live in Seoul\n",
      "AI: AI: That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\n",
      "Human: What is my name?\n",
      "AI: AI: I don't know your name yet! Would you like to share it with me?\n",
      "  Human: My name is Jeseok\n",
      "  Your\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI: Nice to meet you, Jeseok! How do you like living in Seoul?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"My name is Jeseok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "597ebc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "  You are a helpful AI talking a human.\n",
      "\n",
      "  Human: I live in Seoul\n",
      "AI: AI: That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\n",
      "Human: What is my name?\n",
      "AI: AI: I don't know your name yet! Would you like to share it with me?\n",
      "Human: My name is Jeseok\n",
      "AI: AI: Nice to meet you, Jeseok! How do you like living in Seoul?\n",
      "  Human: What is my name?\n",
      "  Your\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"AI: Your name is Jeseok! It's nice to chat with you. What else would you like to talk about?\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "257ca87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: I live in Seoul\\nAI: AI: That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\\nHuman: What is my name?\\nAI: AI: I don't know your name yet! Would you like to share it with me?\\nHuman: My name is Jeseok\\nAI: AI: Nice to meet you, Jeseok! How do you like living in Seoul?\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e1372",
   "metadata": {},
   "source": [
    "## Chat Based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56d697bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: I live in Seoul\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "  llm=llm,\n",
    "  # max_token_limit=80\n",
    "  max_token_limit=120,\n",
    "  memory_key=\"chat_history\",\n",
    "  return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "  MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "  (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "  llm=llm,\n",
    "  memory=memory,\n",
    "  prompt=prompt,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "600a85c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: I live in Seoul\n",
      "AI: That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\n",
      "Human: My name is Jeseok\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Jeseok! How's life in Seoul treating you?\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"My name is Jeseok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08484810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: I live in Seoul\n",
      "AI: That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\n",
      "Human: My name is Jeseok\n",
      "AI: Nice to meet you, Jeseok! How's life in Seoul treating you?\n",
      "Human: What is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Jeseok.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679b27b",
   "metadata": {},
   "source": [
    "## LCEL Based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee34369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "  llm=llm,\n",
    "  # max_token_limit=80\n",
    "  max_token_limit=120,\n",
    "  memory_key=\"chat_history\",\n",
    "  return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "  MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "  (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# def load_memory():\n",
    "def load_memory(_):\n",
    "  # print(input)\n",
    "  return memory.load_memory_variables({})[\"chat_history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(chat_history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "  result = chain.invoke({\n",
    "    \"question\" : question,\n",
    "  })\n",
    "  memory.save_context({\"input\":question}, {\"output\":result.content})\n",
    "  print(result)\n",
    "\n",
    "# chain.invoke({\n",
    "#   # \"chat_history\" : memory.load_memory_variables({})[\"chat_history\"],\n",
    "#   # \"chat_history\" : load_memory(),\n",
    "#   \"question\" : \"My name is Jeseok\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da27ce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Nice to meet you, Jeseok! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 26, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CKeYW5AEeZTqan07UOatySWLSBgfy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--b7225a2d-890b-4f6d-b70f-ff39b6522ba8-0' usage_metadata={'input_tokens': 26, 'output_tokens': 16, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"My name is Jeseok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02ca78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is Jeseok. How can I help you today, Jeseok?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 55, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CKeYs4HDBlP3XOt7oEnKE7WxQ8J4L', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1e4d0146-ad09-4aa0-a871-37e17ba1648d-0' usage_metadata={'input_tokens': 55, 'output_tokens': 18, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7845b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-7-day-challenge (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
