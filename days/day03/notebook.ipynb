{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9a7e45",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20970098",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8973b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# memory = ConversationBufferMemory()\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\" : \"Hi\"}, {\"output\" : \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb93a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\" : \"Hi\"}, {\"output\" : \"How are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb5a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\" : \"Hi\"}, {\"output\" : \"How are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ca6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473447d5",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60d774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "  return_messages=True,\n",
    "  k=5\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "  memory.save_context({\"input\" : input}, {\"output\" : output})\n",
    "\n",
    "add_message(\"1\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae5e9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='0', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='0', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='1', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='1', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='4', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  add_message(str(i), str(i))\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a90d4",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da8a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/x0tx5h514px6gvdl09jdn4rm0000gn/T/ipykernel_1598/1027142467.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.1)\n",
      "/var/folders/42/x0tx5h514px6gvdl09jdn4rm0000gn/T/ipykernel_1598/1027142467.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def add_message(input, output):\n",
    "  memory.save_context({\"input\" : input}, {\"output\" : output})\n",
    "\n",
    "def get_history():\n",
    "  return memory.load_memory_variables({})\n",
    "\n",
    "add_message(\"Hi I'm Jesoek, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ac3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Sung-il infomation high school is so suck\", \"I wish I could go!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11e0014c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human introduces themselves as Jesoek from South Korea. The AI responds with enthusiasm, finding it cool. Jesoek mentions Sung-il Information High School is not great, and the AI expresses a wish to attend.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b341c14",
   "metadata": {},
   "source": [
    "## ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "120f8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m195 packages\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m149 packages\u001b[0m \u001b[2min 24ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfccec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "  llm=llm,\n",
    "  return_messages=True\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "  memory.save_context({\"input\" : input}, {\"output\" : output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b93c6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Hi I'm Jeseok, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82fe5984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Jeseok: Jeseok lives in South Korea.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\" : \"who is Jeseok?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56553b8",
   "metadata": {},
   "source": [
    "## Memory on LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec6e42ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "  you are a helpful AI taling a haman.\n",
      "\n",
      "  []\n",
      "  Human: I live in seoul\n",
      "  Your:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM Chain = Off the shlf : General Perpose chain (일반적인 목적을 가지는 체인)\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "  llm=llm,\n",
    "  max_token_limit=80,\n",
    "  memory_key=\"chat_history\",\n",
    "  return_messages=True,\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "  you are a helpful AI taling a haman.\n",
    "\n",
    "  {chat_history}\n",
    "  Human: {question}\n",
    "  Your:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "  llm=llm,\n",
    "  memory=memory,\n",
    "  # prompt=PromptTemplate.from_template(\"{question}\")\n",
    "  prompt=PromptTemplate.from_template(template=template),\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"I live in seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89c38b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "  you are a helpful AI taling a haman.\n",
      "\n",
      "  [HumanMessage(content='I live in seoul', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\", additional_kwargs={}, response_metadata={})]\n",
      "  Human: Where's do I live?\n",
      "  Your:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You live in Seoul! It's a fascinating city with a lot to offer. What do you like most about it?\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"Where's do I live?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b26f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [SystemMessage(content='The human mentions that they live in Seoul.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"Where's do I live?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"You live in Seoul! It's a fascinating city with a lot to offer. What do you like most about it?\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20077a",
   "metadata": {},
   "source": [
    "## ChatBasedMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f921fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: I live in Seoul\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "  llm=llm,\n",
    "  max_token_limit=120,\n",
    "  memory_key=\"chat_history\",\n",
    "  return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "  MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "  (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "  llm=llm,\n",
    "  memory=memory,\n",
    "  prompt=prompt,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2919408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: I live in Seoul\n",
      "AI: That's great! Seoul is a vibrant city with a rich history and a mix of modern and traditional culture. What do you enjoy most about living there?\n",
      "Human: Where's do I live?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You mentioned that you live in Seoul, which is the capital city of South Korea. It's known for its bustling urban life, historical sites, and cultural landmarks. If you have specific areas or neighborhoods in mind, I can provide more information about them!\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"Where's do I live?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab023bfd",
   "metadata": {},
   "source": [
    "## LCEL Based Memory (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10fb946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "  llm=llm,\n",
    "  max_token_limit=120,\n",
    "  memory_key=\"chat_history\",\n",
    "  return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "  MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "  (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def load_memory(_):\n",
    "  return memory.load_memory_variables({})[\"chat_history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(chat_history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "  result = chain.invoke({\n",
    "    \"question\": question\n",
    "  })\n",
    "  memory.save_context({\"input\" : question}, {\"output\" : result.content})\n",
    "  print(result)\n",
    "\n",
    "# chain.invoke(\n",
    "#   {\n",
    "#     # \"chat_history\" : memory.load_memory_variables({})[\"chat_history\"],\n",
    "#     \"chat_history\" : load_memory(),\n",
    "#     \"question\" : \"My name is Jeseok\"\n",
    "#   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfd89e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Nice to meet you, Jeseok! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 26, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CKhZaBNm22GYR76fXN9XqUFaWiOcY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f8142962-b75a-49f5-ac20-dc7583acc595-0' usage_metadata={'input_tokens': 26, 'output_tokens': 16, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"My name is Jeseok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3cf4fe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is Jeseok. How can I help you today, Jeseok?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 55, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CKhZkjnxFmsbDU4MczKpuG6U07SL4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d5b6fd24-543c-4a1f-a8f3-e23617144ab9-0' usage_metadata={'input_tokens': 55, 'output_tokens': 18, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a75be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-7-day-challenge (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
